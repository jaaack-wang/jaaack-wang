<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta name="title" content="LVLMs are Bad at Overhearing Human Referential Communication - Zhengxiang Wang et al.">
  <meta name="description" content="Evaluation of large vision language models as overhearers in spontaneous human referential communication.">
  <meta name="keywords" content="LVLM, referential communication, overhearing, multimodal reasoning, NLP">
  <meta name="author" content="Zhengxiang Wang, Weiling Li, Panagiotis Kaliosis, Owen Rambow, Susan E. Brennan">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Zhengxiang Wang">
  <meta property="og:title" content="LVLMs are Bad at Overhearing Human Referential Communication">
  <meta property="og:description" content="Evaluating LVLMs on overheard human referential communication.">
  <meta property="og:url" content="https://www.zhengxiang-wang.me/papers/lvlms-overhearing/">
  <meta property="og:image" content="https://www.zhengxiang-wang.me/images/research/lvlm_overhearing.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="LVLMs are Bad at Overhearing Human Referential Communication">
  <meta name="twitter:description" content="Evaluating LVLMs on overheard human referential communication.">
  <meta name="twitter:image" content="https://www.zhengxiang-wang.me/images/research/lvlm_overhearing.png">

  <meta name="citation_title" content="LVLMs are Bad at Overhearing Human Referential Communication">
  <meta name="citation_author" content="Wang, Zhengxiang">
  <meta name="citation_author" content="Li, Weiling">
  <meta name="citation_author" content="Kaliosis, Panagiotis">
  <meta name="citation_author" content="Rambow, Owen">
  <meta name="citation_author" content="Brennan, Susan E.">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="EMNLP 2025 (Main)">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2509.11514.pdf">

  <title>LVLMs are Bad at Overhearing Human Referential Communication</title>

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
</head>
<body>
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="/papers/time-puzzles/" class="work-item">
          <div class="work-info">
            <h5>Measuring Iterative Temporal Reasoning with Time Puzzles</h5>
            <p>Constraint-based date inference benchmark for iterative temporal reasoning.</p>
            <span class="work-venue">Preprint 2026</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="/papers/lvlms-overhearing/" class="work-item">
          <div class="work-info">
            <h5>LVLMs are Bad at Overhearing Human Referential Communication</h5>
            <p>Evaluation of LVLM limitations in overhearing settings.</p>
            <span class="work-venue">EMNLP 2025 Main</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="/papers/implicit-writing-styles/" class="work-item">
          <div class="work-info">
            <h5>Catch Me If You Can? Not Yet</h5>
            <p>LLMs still struggle to imitate implicit writing styles of everyday authors.</p>
            <span class="work-venue">EMNLP 2025 Findings</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">LVLMs are Bad at Overhearing Human Referential Communication</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><a href="https://www.zhengxiang-wang.me/" target="_blank" rel="noopener">Zhengxiang Wang</a>,</span>
                <span class="author-block">Weiling Li,</span>
                <span class="author-block">Panagiotis Kaliosis,</span>
                <span class="author-block">Owen Rambow,</span>
                <span class="author-block">Susan E. Brennan</span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block">EMNLP 2025 (Main)</span>
              </div>
              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2509.11514.pdf" target="_blank" rel="noopener"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fas fa-file-pdf"></i></span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://github.com/jaaack-wang/lvlms-overhearing" target="_blank" rel="noopener"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fab fa-github"></i></span>
                      <span>Code</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2509.11514" target="_blank" rel="noopener"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="ai ai-arxiv"></i></span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                During spontaneous conversations, speakers collaborate on novel referring expressions,
                which they can then re-use in subsequent conversations. Understanding such referring
                expressions is an important ability for an embodied agent, requiring integrated language,
                vision, and conversational reasoning. We evaluate seven state-of-the-art LVLMs as
                overhearers on a corpus of spontaneous human conversations in a collaborative object-matching
                task. We find that the task remains challenging for current LVLMs and that models fail to
                show consistent improvement as they overhear more repeated rounds from the same discourse
                participants.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Main Results</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="../../images/research/lvlm_overhearing.png" alt="LVLM overhearing results" loading="lazy">
              <h2 class="subtitle has-text-centered">Performance remains limited and does not consistently improve across repeated overheard rounds.</h2>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Conclusion</h2>
            <div class="content has-text-justified">
              <p>
                Current LVLMs still struggle to robustly ground overheard human referential communication,
                even in repeated interaction settings where conversational context accumulates. The findings
                point to a persistent gap in multimodal conversational grounding and motivate stronger methods
                for integrating discourse history, visual context, and reference tracking.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@article{wang2025lvlms,
  title={LVLMs are Bad at Overhearing Human Referential Communication},
  author={Wang, Zhengxiang and Li, Weiling and Kaliosis, Panagiotis and Rambow, Owen and Brennan, Susan E.},
  journal={arXiv preprint arXiv:2509.11514},
  year={2025},
  url={https://arxiv.org/abs/2509.11514}
}</code></pre>
      </div>
    </section>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank" rel="noopener">Academic Project Page Template</a>,
              adopted from the <a href="https://nerfies.github.io" target="_blank" rel="noopener">Nerfies</a> project page.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>
